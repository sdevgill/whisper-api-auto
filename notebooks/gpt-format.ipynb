{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import openai\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = \"\\n--------------------------------\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_and_token_count(transcript,\n",
    "                                   model=\"gpt-3.5-turbo-16k\",\n",
    "                                   temperature=0,\n",
    "                                   max_tokens=8192):\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content':\n",
    "                    \"\"\"\n",
    "                    This is a transcript. Your task is to format this transcript into clear, readable paragraphs.\\\n",
    "                    You should not change any of the content, nor should you add any summaries or bullet points.\n",
    "                    \"\"\"\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': transcript\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message[\"content\"]\n",
    "\n",
    "    token_dict = {\n",
    "        'prompt_tokens': response['usage']['prompt_tokens'],\n",
    "        'completion_tokens': response['usage']['completion_tokens'],\n",
    "        'total_tokens': response['usage']['total_tokens'],\n",
    "    }\n",
    "\n",
    "    return content, token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the transcript\n",
    "def process_transcript(input_file, output_folder):\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        transcript = file.read()\n",
    "\n",
    "    formatted_transcript, token_dict = get_completion_and_token_count(transcript)\n",
    "\n",
    "    output_file_name = os.path.splitext(os.path.basename(input_file))[0] + \"_gpt.txt\"\n",
    "    output_file_path = os.path.join(output_folder, output_file_name)\n",
    "\n",
    "    with open(output_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(separator)\n",
    "        file.write(formatted_transcript)\n",
    "        file.write(separator)\n",
    "        file.write(f\"\\nTokens: {token_dict}\")\n",
    "        file.write(f\"\\nCost: ${token_dict['total_tokens'] * 0.000002:.6f}\")\n",
    "\n",
    "    print(\n",
    "        f\"Processed '{input_file}' with gpt.\\nTokens: {token_dict},\\nCost: ${token_dict['total_tokens'] * 0.000002:.6f}\"\n",
    "    )\n",
    "\n",
    "    return token_dict['total_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all transcripts in the folder\n",
    "def process_all_transcripts(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    total_tokens = 0\n",
    "    \n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            input_file_path = os.path.join(input_folder, file_name)\n",
    "            transcript_tokens = process_transcript(input_file_path, output_folder)\n",
    "            total_tokens += transcript_tokens\n",
    "\n",
    "    return total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(separator)\n",
    "    print(\"Starting gpt formatting...\\n\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    input_folder = \"./output\"\n",
    "    gpt_output_folder = \"./gpt_output\"\n",
    "\n",
    "    total_tokens = process_all_transcripts(input_folder, gpt_output_folder)\n",
    "    total_cost = total_tokens * 0.000002\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "\n",
    "    print(f\"\\nTotal tokens: {total_tokens}\")\n",
    "    print(f\"Total cost: ${total_cost:.6f}\")\n",
    "    print(f\"Time taken: {time_taken:.2f} seconds\")\n",
    "    print(separator)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
